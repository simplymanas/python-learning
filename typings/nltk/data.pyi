"""
This type stub file was generated by pyright.
"""

import os
import sys
import zipfile
from abc import ABCMeta, abstractmethod
from gzip import GzipFile
from six import add_metaclass, text_type
from nltk.compat import py3_data
from typing import Any, Optional

"""
Functions to find and load NLTK resource files, such as corpora,
grammars, and saved processing objects.  Resource files are identified
using URLs, such as ``nltk:corpora/abc/rural.txt`` or
``http://nltk.org/sample/toy.cfg``.  The following URL protocols are
supported:

  - ``file:path``: Specifies the file whose path is *path*.
    Both relative and absolute paths may be used.

  - ``http://host/path``: Specifies the file stored on the web
    server *host* at path *path*.

  - ``nltk:path``: Specifies the file stored in the NLTK data
    package at *path*.  NLTK will search for these files in the
    directories specified by ``nltk.data.path``.

If no protocol is specified, then the default protocol ``nltk:`` will
be used.

This module provides to functions that can be used to access a
resource file, given its URL: ``load()`` loads a given resource, and
adds it to a resource cache; and ``retrieve()`` copies a given resource
to a local file.
"""
path = []
_paths_from_env = os.environ.get('NLTK_DATA', str('')).split(os.pathsep)
if 'APPENGINE_RUNTIME' not in os.environ and os.path.expanduser('~/') != '~/':
    ...
if sys.platform.startswith('win'):
    ...
else:
    ...
def gzip_open_unicode(filename, mode=..., compresslevel=..., encoding=..., fileobj: Optional[Any] = ..., errors: Optional[Any] = ..., newline: Optional[Any] = ...):
    ...

def split_resource_url(resource_url):
    """
    Splits a resource url into "<protocol>:<path>".

    >>> windows = sys.platform.startswith('win')
    >>> split_resource_url('nltk:home/nltk')
    ('nltk', 'home/nltk')
    >>> split_resource_url('nltk:/home/nltk')
    ('nltk', '/home/nltk')
    >>> split_resource_url('file:/home/nltk')
    ('file', '/home/nltk')
    >>> split_resource_url('file:///home/nltk')
    ('file', '/home/nltk')
    >>> split_resource_url('file:///C:/home/nltk')
    ('file', '/C:/home/nltk')
    """
    ...

def normalize_resource_url(resource_url):
    r"""
    Normalizes a resource url

    >>> windows = sys.platform.startswith('win')
    >>> os.path.normpath(split_resource_url(normalize_resource_url('file:grammar.fcfg'))[1]) == \
    ... ('\\' if windows else '') + os.path.abspath(os.path.join(os.curdir, 'grammar.fcfg'))
    True
    >>> not windows or normalize_resource_url('file:C:/dir/file') == 'file:///C:/dir/file'
    True
    >>> not windows or normalize_resource_url('file:C:\\dir\\file') == 'file:///C:/dir/file'
    True
    >>> not windows or normalize_resource_url('file:C:\\dir/file') == 'file:///C:/dir/file'
    True
    >>> not windows or normalize_resource_url('file://C:/dir/file') == 'file:///C:/dir/file'
    True
    >>> not windows or normalize_resource_url('file:////C:/dir/file') == 'file:///C:/dir/file'
    True
    >>> not windows or normalize_resource_url('nltk:C:/dir/file') == 'file:///C:/dir/file'
    True
    >>> not windows or normalize_resource_url('nltk:C:\\dir\\file') == 'file:///C:/dir/file'
    True
    >>> windows or normalize_resource_url('file:/dir/file/toy.cfg') == 'file:///dir/file/toy.cfg'
    True
    >>> normalize_resource_url('nltk:home/nltk')
    'nltk:home/nltk'
    >>> windows or normalize_resource_url('nltk:/home/nltk') == 'file:///home/nltk'
    True
    >>> normalize_resource_url('http://example.com/dir/file')
    'http://example.com/dir/file'
    >>> normalize_resource_url('dir/file')
    'nltk:dir/file'
    """
    ...

def normalize_resource_name(resource_name, allow_relative: bool = ..., relative_path: Optional[Any] = ...):
    """
    :type resource_name: str or unicode
    :param resource_name: The name of the resource to search for.
        Resource names are posix-style relative path names, such as
        ``corpora/brown``.  Directory names will automatically
        be converted to a platform-appropriate path separator.
        Directory trailing slashes are preserved

    >>> windows = sys.platform.startswith('win')
    >>> normalize_resource_name('.', True)
    './'
    >>> normalize_resource_name('./', True)
    './'
    >>> windows or normalize_resource_name('dir/file', False, '/') == '/dir/file'
    True
    >>> not windows or normalize_resource_name('C:/file', False, '/') == '/C:/file'
    True
    >>> windows or normalize_resource_name('/dir/file', False, '/') == '/dir/file'
    True
    >>> windows or normalize_resource_name('../dir/file', False, '/') == '/dir/file'
    True
    >>> not windows or normalize_resource_name('/dir/file', True, '/') == 'dir/file'
    True
    >>> windows or normalize_resource_name('/dir/file', True, '/') == '/dir/file'
    True
    """
    ...

@add_metaclass(ABCMeta)
class PathPointer(object):
    """
    An abstract base class for 'path pointers,' used by NLTK's data
    package to identify specific paths.  Two subclasses exist:
    ``FileSystemPathPointer`` identifies a file that can be accessed
    directly via a given absolute path.  ``ZipFilePathPointer``
    identifies a file contained within a zipfile, that can be accessed
    by reading that zipfile.
    """
    @abstractmethod
    def open(self, encoding: Optional[Any] = ...):
        """
        Return a seekable read-only stream that can be used to read
        the contents of the file identified by this path pointer.

        :raise IOError: If the path specified by this pointer does
            not contain a readable file.
        """
        ...
    
    @abstractmethod
    def file_size(self):
        """
        Return the size of the file pointed to by this path pointer,
        in bytes.

        :raise IOError: If the path specified by this pointer does
            not contain a readable file.
        """
        ...
    
    @abstractmethod
    def join(self, fileid):
        """
        Return a new path pointer formed by starting at the path
        identified by this pointer, and then following the relative
        path given by ``fileid``.  The path components of ``fileid``
        should be separated by forward slashes, regardless of
        the underlying file system's path seperator character.
        """
        ...
    


class FileSystemPathPointer(PathPointer, text_type):
    """
    A path pointer that identifies a file which can be accessed
    directly via a given absolute path.
    """
    @py3_data
    def __init__(self, _path):
        """
        Create a new path pointer for the given absolute path.

        :raise IOError: If the given path does not exist.
        """
        ...
    
    @property
    def path(self):
        """The absolute path identified by this path pointer."""
        ...
    
    def open(self, encoding: Optional[Any] = ...):
        ...
    
    def file_size(self):
        ...
    
    def join(self, fileid):
        ...
    
    def __repr__(self):
        ...
    
    def __str__(self):
        ...
    


class BufferedGzipFile(GzipFile):
    """
    A ``GzipFile`` subclass that buffers calls to ``read()`` and ``write()``.
    This allows faster reads and writes of data to and from gzip-compressed
    files at the cost of using more memory.

    The default buffer size is 2MB.

    ``BufferedGzipFile`` is useful for loading large gzipped pickle objects
    as well as writing large encoded feature files for classifier training.
    """
    MB = ...
    SIZE = ...
    @py3_data
    def __init__(self, filename: Optional[Any] = ..., mode: Optional[Any] = ..., compresslevel=..., fileobj: Optional[Any] = ..., **kwargs):
        """
        Return a buffered gzip file object.

        :param filename: a filesystem path
        :type filename: str
        :param mode: a file mode which can be any of 'r', 'rb', 'a', 'ab',
            'w', or 'wb'
        :type mode: str
        :param compresslevel: The compresslevel argument is an integer from 1
            to 9 controlling the level of compression; 1 is fastest and
            produces the least compression, and 9 is slowest and produces the
            most compression. The default is 9.
        :type compresslevel: int
        :param fileobj: a BytesIO stream to read from instead of a file.
        :type fileobj: BytesIO
        :param size: number of bytes to buffer during calls to read() and write()
        :type size: int
        :rtype: BufferedGzipFile
        """
        ...
    
    def _reset_buffer(self):
        ...
    
    def _write_buffer(self, data):
        ...
    
    def _write_gzip(self, data):
        ...
    
    def close(self):
        ...
    
    def flush(self, lib_mode=...):
        ...
    
    def read(self, size: Optional[Any] = ...):
        ...
    
    def write(self, data, size=...):
        """
        :param data: bytes to write to file or buffer
        :type data: bytes
        :param size: buffer at least size bytes before writing to file
        :type size: int
        """
        ...
    


class GzipFileSystemPathPointer(FileSystemPathPointer):
    """
    A subclass of ``FileSystemPathPointer`` that identifies a gzip-compressed
    file located at a given absolute path.  ``GzipFileSystemPathPointer`` is
    appropriate for loading large gzip-compressed pickle objects efficiently.
    """
    def open(self, encoding: Optional[Any] = ...):
        ...
    


class ZipFilePathPointer(PathPointer):
    """
    A path pointer that identifies a file contained within a zipfile,
    which can be accessed by reading that zipfile.
    """
    @py3_data
    def __init__(self, zipfile, entry=...):
        """
        Create a new path pointer pointing at the specified entry
        in the given zipfile.

        :raise IOError: If the given zipfile does not exist, or if it
        does not contain the specified entry.
        """
        ...
    
    @property
    def zipfile(self):
        """
        The zipfile.ZipFile object used to access the zip file
        containing the entry identified by this path pointer.
        """
        ...
    
    @property
    def entry(self):
        """
        The name of the file within zipfile that this path
        pointer points to.
        """
        ...
    
    def open(self, encoding: Optional[Any] = ...):
        ...
    
    def file_size(self):
        ...
    
    def join(self, fileid):
        ...
    
    def __repr__(self):
        ...
    
    def __str__(self):
        ...
    


_resource_cache = {  }
def find(resource_name, paths: Optional[Any] = ...):
    """
    Find the given resource by searching through the directories and
    zip files in paths, where a None or empty string specifies an absolute path.
    Returns a corresponding path name.  If the given resource is not
    found, raise a ``LookupError``, whose message gives a pointer to
    the installation instructions for the NLTK downloader.

    Zip File Handling:

      - If ``resource_name`` contains a component with a ``.zip``
        extension, then it is assumed to be a zipfile; and the
        remaining path components are used to look inside the zipfile.

      - If any element of ``nltk.data.path`` has a ``.zip`` extension,
        then it is assumed to be a zipfile.

      - If a given resource name that does not contain any zipfile
        component is not found initially, then ``find()`` will make a
        second attempt to find that resource, by replacing each
        component *p* in the path with *p.zip/p*.  For example, this
        allows ``find()`` to map the resource name
        ``corpora/chat80/cities.pl`` to a zip file path pointer to
        ``corpora/chat80.zip/chat80/cities.pl``.

      - When using ``find()`` to locate a directory contained in a
        zipfile, the resource name must end with the forward slash
        character.  Otherwise, ``find()`` will not locate the
        directory.

    :type resource_name: str or unicode
    :param resource_name: The name of the resource to search for.
        Resource names are posix-style relative path names, such as
        ``corpora/brown``.  Directory names will be
        automatically converted to a platform-appropriate path separator.
    :rtype: str
    """
    ...

def retrieve(resource_url, filename: Optional[Any] = ..., verbose: bool = ...):
    """
    Copy the given resource to a local file.  If no filename is
    specified, then use the URL's filename.  If there is already a
    file named ``filename``, then raise a ``ValueError``.

    :type resource_url: str
    :param resource_url: A URL specifying where the resource should be
        loaded from.  The default protocol is "nltk:", which searches
        for the file in the the NLTK data package.
    """
    ...

FORMATS = { 'pickle': "A serialized python object, stored using the pickle module.",'json': "A serialized python object, stored using the json module.",'yaml': "A serialized python object, stored using the yaml module.",'cfg': "A context free grammar.",'pcfg': "A probabilistic CFG.",'fcfg': "A feature CFG.",'fol': "A list of first order logic expressions, parsed with " "nltk.sem.logic.Expression.fromstring.",'logic': "A list of first order logic expressions, parsed with " "nltk.sem.logic.LogicParser.  Requires an additional logic_parser " "parameter",'val': "A semantic valuation, parsed by nltk.sem.Valuation.fromstring.",'raw': "The raw (byte string) contents of a file.",'text': "The raw (unicode string) contents of a file. " }
AUTO_FORMATS = { 'pickle': 'pickle','json': 'json','yaml': 'yaml','cfg': 'cfg','pcfg': 'pcfg','fcfg': 'fcfg','fol': 'fol','logic': 'logic','val': 'val','txt': 'text','text': 'text' }
def load(resource_url, format=..., cache: bool = ..., verbose: bool = ..., logic_parser: Optional[Any] = ..., fstruct_reader: Optional[Any] = ..., encoding: Optional[Any] = ...):
    """
    Load a given resource from the NLTK data package.  The following
    resource formats are currently supported:

      - ``pickle``
      - ``json``
      - ``yaml``
      - ``cfg`` (context free grammars)
      - ``pcfg`` (probabilistic CFGs)
      - ``fcfg`` (feature-based CFGs)
      - ``fol`` (formulas of First Order Logic)
      - ``logic`` (Logical formulas to be parsed by the given logic_parser)
      - ``val`` (valuation of First Order Logic model)
      - ``text`` (the file contents as a unicode string)
      - ``raw`` (the raw file contents as a byte string)

    If no format is specified, ``load()`` will attempt to determine a
    format based on the resource name's file extension.  If that
    fails, ``load()`` will raise a ``ValueError`` exception.

    For all text formats (everything except ``pickle``, ``json``, ``yaml`` and ``raw``),
    it tries to decode the raw contents using UTF-8, and if that doesn't
    work, it tries with ISO-8859-1 (Latin-1), unless the ``encoding``
    is specified.

    :type resource_url: str
    :param resource_url: A URL specifying where the resource should be
        loaded from.  The default protocol is "nltk:", which searches
        for the file in the the NLTK data package.
    :type cache: bool
    :param cache: If true, add this resource to a cache.  If load()
        finds a resource in its cache, then it will return it from the
        cache rather than loading it.
    :type verbose: bool
    :param verbose: If true, print a message when loading a resource.
        Messages are not displayed when a resource is retrieved from
        the cache.
    :type logic_parser: LogicParser
    :param logic_parser: The parser that will be used to parse logical
        expressions.
    :type fstruct_reader: FeatStructReader
    :param fstruct_reader: The parser that will be used to parse the
        feature structure of an fcfg.
    :type encoding: str
    :param encoding: the encoding of the input; only used for text formats.
    """
    ...

def show_cfg(resource_url, escape=...):
    """
    Write out a grammar file, ignoring escaped and empty lines.

    :type resource_url: str
    :param resource_url: A URL specifying where the resource should be
        loaded from.  The default protocol is "nltk:", which searches
        for the file in the the NLTK data package.
    :type escape: str
    :param escape: Prepended string that signals lines to be ignored
    """
    ...

def clear_cache():
    """
    Remove all objects from the resource cache.
    :see: load()
    """
    ...

def _open(resource_url):
    """
    Helper function that returns an open file object for a resource,
    given its resource URL.  If the given resource URL uses the "nltk:"
    protocol, or uses no protocol, then use ``nltk.data.find`` to find
    its path, and open it with the given mode; if the resource URL
    uses the 'file' protocol, then open the file with the given mode;
    otherwise, delegate to ``urllib2.urlopen``.

    :type resource_url: str
    :param resource_url: A URL specifying where the resource should be
        loaded from.  The default protocol is "nltk:", which searches
        for the file in the the NLTK data package.
    """
    ...

class LazyLoader(object):
    @py3_data
    def __init__(self, _path):
        ...
    
    def __load(self):
        self.__dict__ = ...
        self.__class__ = ...
    
    def __getattr__(self, attr):
        ...
    
    def __repr__(self):
        ...
    


class OpenOnDemandZipFile(zipfile.ZipFile):
    """
    A subclass of ``zipfile.ZipFile`` that closes its file pointer
    whenever it is not using it; and re-opens it when it needs to read
    data from the zipfile.  This is useful for reducing the number of
    open file handles when many zip files are being accessed at once.
    ``OpenOnDemandZipFile`` must be constructed from a filename, not a
    file-like object (to allow re-opening).  ``OpenOnDemandZipFile`` is
    read-only (i.e. ``write()`` and ``writestr()`` are disabled.
    """
    @py3_data
    def __init__(self, filename):
        ...
    
    def read(self, name):
        self.fp = ...
    
    def write(self, *args, **kwargs):
        """:raise NotImplementedError: OpenOnDemandZipfile is read-only"""
        ...
    
    def writestr(self, *args, **kwargs):
        """:raise NotImplementedError: OpenOnDemandZipfile is read-only"""
        ...
    
    def __repr__(self):
        ...
    


class SeekableUnicodeStreamReader(object):
    """
    A stream reader that automatically encodes the source byte stream
    into unicode (like ``codecs.StreamReader``); but still supports the
    ``seek()`` and ``tell()`` operations correctly.  This is in contrast
    to ``codecs.StreamReader``, which provide *broken* ``seek()`` and
    ``tell()`` methods.

    This class was motivated by ``StreamBackedCorpusView``, which
    makes extensive use of ``seek()`` and ``tell()``, and needs to be
    able to handle unicode-encoded files.

    Note: this class requires stateless decoders.  To my knowledge,
    this shouldn't cause a problem with any of python's builtin
    unicode encodings.
    """
    DEBUG = ...
    @py3_data
    def __init__(self, stream, encoding, errors=...):
        self.stream = ...
        self.encoding = ...
        self.errors = ...
        self.decode = ...
        self.bytebuffer = ...
        self.linebuffer = ...
    
    def read(self, size: Optional[Any] = ...):
        """
        Read up to ``size`` bytes, decode them using this reader's
        encoding, and return the resulting unicode string.

        :param size: The maximum number of bytes to read.  If not
            specified, then read as many bytes as possible.
        :type size: int
        :rtype: unicode
        """
        ...
    
    def discard_line(self):
        ...
    
    def readline(self, size: Optional[Any] = ...):
        """
        Read a line of text, decode it using this reader's encoding,
        and return the resulting unicode string.

        :param size: The maximum number of bytes to read.  If no
            newline is encountered before ``size`` bytes have been read,
            then the returned value may not be a complete line of text.
        :type size: int
        """
        ...
    
    def readlines(self, sizehint: Optional[Any] = ..., keepends: bool = ...):
        """
        Read this file's contents, decode them using this reader's
        encoding, and return it as a list of unicode lines.

        :rtype: list(unicode)
        :param sizehint: Ignored.
        :param keepends: If false, then strip newlines.
        """
        ...
    
    def next(self):
        """Return the next decoded line from the underlying stream."""
        ...
    
    def __next__(self):
        ...
    
    def __iter__(self):
        """Return self"""
        ...
    
    def __del__(self):
        ...
    
    def xreadlines(self):
        """Return self"""
        ...
    
    @property
    def closed(self):
        """True if the underlying stream is closed."""
        ...
    
    @property
    def name(self):
        """The name of the underlying stream."""
        ...
    
    @property
    def mode(self):
        """The mode of the underlying stream."""
        ...
    
    def close(self):
        """
        Close the underlying stream.
        """
        ...
    
    def seek(self, offset, whence=...):
        """
        Move the stream to a new file position.  If the reader is
        maintaining any buffers, then they will be cleared.

        :param offset: A byte count offset.
        :param whence: If 0, then the offset is from the start of the file
            (offset should be positive), if 1, then the offset is from the
            current position (offset may be positive or negative); and if 2,
            then the offset is from the end of the file (offset should
            typically be negative).
        """
        self.linebuffer = ...
        self.bytebuffer = ...
    
    def char_seek_forward(self, offset):
        """
        Move the read pointer forward by ``offset`` characters.
        """
        ...
    
    def _char_seek_forward(self, offset, est_bytes: Optional[Any] = ...):
        """
        Move the file position forward by ``offset`` characters,
        ignoring all buffers.

        :param est_bytes: A hint, giving an estimate of the number of
            bytes that will be needed to move forward by ``offset`` chars.
            Defaults to ``offset``.
        """
        ...
    
    def tell(self):
        """
        Return the current file position on the underlying byte
        stream.  If this reader is maintaining any buffers, then the
        returned file position will be the position of the beginning
        of those buffers.
        """
        ...
    
    def _read(self, size: Optional[Any] = ...):
        """
        Read up to ``size`` bytes from the underlying stream, decode
        them using this reader's encoding, and return the resulting
        unicode string.  ``linebuffer`` is not included in the result.
        """
        self.bytebuffer = ...
    
    def _incr_decode(self, bytes):
        """
        Decode the given byte string into a unicode string, using this
        reader's encoding.  If an exception is encountered that
        appears to be caused by a truncation error, then just decode
        the byte string without the bytes that cause the trunctaion
        error.

        Return a tuple ``(chars, num_consumed)``, where ``chars`` is
        the decoded unicode string, and ``num_consumed`` is the
        number of bytes that were consumed.
        """
        ...
    
    _BOM_TABLE = ...
    def _check_bom(self):
        ...
    


__all__ = ['path', 'PathPointer', 'FileSystemPathPointer', 'BufferedGzipFile', 'GzipFileSystemPathPointer', 'GzipFileSystemPathPointer', 'find', 'retrieve', 'FORMATS', 'AUTO_FORMATS', 'load', 'show_cfg', 'clear_cache', 'LazyLoader', 'OpenOnDemandZipFile', 'GzipFileSystemPathPointer', 'SeekableUnicodeStreamReader']
