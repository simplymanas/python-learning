"""
This type stub file was generated by pyright.
"""

from nltk.tokenize.api import TokenizerI
from typing import Any, Optional

_stanford_url = 'https://nlp.stanford.edu/software/tokenizer.shtml'
class StanfordTokenizer(TokenizerI):
    r"""
    Interface to the Stanford Tokenizer

    >>> from nltk.tokenize.stanford import StanfordTokenizer
    >>> s = "Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks."
    >>> StanfordTokenizer().tokenize(s)
    ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']
    >>> s = "The colour of the wall is blue."
    >>> StanfordTokenizer(options={"americanize": True}).tokenize(s)
    ['The', 'color', 'of', 'the', 'wall', 'is', 'blue', '.']
    """
    _JAR = ...
    def __init__(self, path_to_jar: Optional[Any] = ..., encoding=..., options: Optional[Any] = ..., verbose: bool = ..., java_options=...):
        self.java_options = ...
    
    @staticmethod
    def _parse_tokenized_output(s):
        ...
    
    def tokenize(self, s):
        """
        Use stanford tokenizer's PTBTokenizer to tokenize multiple sentences.
        """
        ...
    
    def _execute(self, cmd, input_, verbose: bool = ...):
        ...
    


def setup_module(module):
    ...

